{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random \n",
    "import torch\n",
    "from torch.autograd import Variable\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images=np.load('data/images.npy')\n",
    "labels=np.load('data/labels.npy')\n",
    "labels=labels.astype(int)\n",
    "labels[labels!=0]=-1\n",
    "labels[labels==0]=1\n",
    "labels[labels==-1]=0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number of apples in the test set = 10000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x119d7e860>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10cad2a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apples=images[labels==1]\n",
    "print(len(apples))\n",
    "plt.imshow(apples[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flattening the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shape_images_flat=(images.shape[0],images.shape[1]*images.shape[2])\n",
    "images_flat=np.ndarray(shape=shape_images_flat)\n",
    "for index in range(len(images)):\n",
    "    images_flat[index]=images[index].flat\n",
    "images=images_flat\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_len=len(images)\n",
    "shuffler_list=list(range(0, images_len))\n",
    "# print(list)\n",
    "# random.shuffle(shuffler_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "shuffled_images=images[shuffler_list]\n",
    "shuffled_labels=labels[shuffler_list]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_images=shuffled_images[0:40000]\n",
    "train_labels=shuffled_labels[0:40000]\n",
    "\n",
    "validation_images=shuffled_images[40000:45000]\n",
    "validation_labels=shuffled_labels[40000:45000]\n",
    "\n",
    "test_images=shuffled_images[45000:50000]\n",
    "test_labels=shuffled_labels[45000:50000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random coin flipping accuracy\n",
    "Random coin flipping gives us:\n",
    "1. Correct prediction Probabilty=0.5 if apple\n",
    "2. Correct prediction Probabilty=0.5 if not apple\n",
    "\n",
    "Probabilty of apple=0.2\n",
    "\n",
    "Probabilty of not apple=0.8\n",
    "\n",
    "Overall correct clasification probabilty =0.5 x 0.2 + 0.5 x 0.8\n",
    "\n",
    "Overall accuracy thus is=0.5\n",
    "\n",
    "# Majority Classifier accuracy\n",
    "We always predict not apple in this case\n",
    "\n",
    "Probabilty of not apple=0.8\n",
    "\n",
    "Thus, majority classifer accuracy=0.8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def accuracy(y, y_hat):\n",
    "    \"\"\"Compute accuracy.\n",
    "    Args:\n",
    "    y: A 1-D int NumPy array.\n",
    "    y_hat: A 1-D int NumPy array.\n",
    "    Returns:\n",
    "    A float, the fraction of time y[i] == y_hat[i].\n",
    "    \"\"\"\n",
    "    return (y == y_hat).astype(np.float).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-70-c92c7eaeb793>, line 9)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-70-c92c7eaeb793>\"\u001b[0;36m, line \u001b[0;32m9\u001b[0m\n\u001b[0;31m    y=train_labels\u001b[0m\n\u001b[0m                  ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "# train_labels[train_labels==0]=1\n",
    "# train_labels[train_labels!=0]=-1\n",
    "# X = torch.from_numpy(train_images)\n",
    "# y = torch.from_numpy(train_labels)\n",
    "X=train_images\n",
    "y=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sign(num):\n",
    "    check = Variable(torch.Tensor([0.0]).double().expand(num.size()))\n",
    "    return torch.ge(num,check).double()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_epochs=3\n",
    "learning_rate=0.001\n",
    "Y=train_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 676])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "there are no graph nodes that require computing gradients",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-73-e99611038c60>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mY_tensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my_hat\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m         \u001b[0mJ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m         \u001b[0mW_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0mlearning_rate\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mW_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensor_env/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    154\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m         \"\"\"\n\u001b[0;32m--> 156\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda/envs/tensor_env/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 98\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: there are no graph nodes that require computing gradients"
     ]
    }
   ],
   "source": [
    "X=train_images\n",
    "Y=train_labels\n",
    "W_tensor=torch.torch.DoubleTensor(1,X.shape[1]).zero_()\n",
    "print(W_tensor.shape)\n",
    "\n",
    "W_tensor=Variable(W_tensor,requires_grad=True)\n",
    "X_tensor=Variable(torch.from_numpy(X))\n",
    "Y_tensor=Variable(torch.from_numpy(Y.astype(float)))\n",
    "for epoch in range(0,total_epochs):\n",
    "#     for i in range(0,X.shape[0]):\n",
    "    for i in range(0,1):\n",
    "\n",
    "        w_x = X_tensor[i].view(1,-1).mm(W_tensor.t())\n",
    "        y_hat = sign(w_x)\n",
    "        loss = (Y_tensor[i] - y_hat )\n",
    "        J = loss* y_pred \n",
    "        loss.backward()\n",
    "        W_tensor.data -= learning_rate * W_tensor.grad.data\n",
    "\n",
    "        \n",
    "weights_overall=W_tensor.data.numpy()\n",
    "print(weights_overall.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "   0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "print(weights_overall)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.800175\n"
     ]
    }
   ],
   "source": [
    "X=train_images\n",
    "y=train_labels\n",
    "d=X.dot(weights_overall)\n",
    "d[d>0]=1\n",
    "d[d<=0]=0\n",
    "ac=accuracy(y,d)\n",
    "print(ac)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 1 1 ..., 1 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
